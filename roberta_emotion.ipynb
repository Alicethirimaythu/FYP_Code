{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 25 23:30:20 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.52                 Driver Version: 551.52         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 44%   29C    P8             13W /  125W |     949MiB /   6144MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4424    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      7504    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A      8204    C+G   ...wekyb3d8bbwe\\XboxGameBarWidgets.exe      N/A      |\n",
      "|    0   N/A  N/A      8372    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     12684    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     13844    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14848    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15748    C+G   ...42.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     15952    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18192    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     18228    C+G   ...al\\Discord\\app-1.0.9037\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     19612    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     24264    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     24280    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     25148    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     25272    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     28296    C+G   ...pdnekdrzrea0\\XboxGameBarSpotify.exe      N/A      |\n",
      "|    0   N/A  N/A     28308    C+G   ...m Files (x86)\\Overwolf\\Overwolf.exe      N/A      |\n",
      "|    0   N/A  N/A     28904    C+G   ...on\\122.0.2365.92\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     29376    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     29704    C+G   ...al\\Discord\\app-1.0.9037\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     31232    C+G   ...rwolf\\0.242.1.6\\OverwolfBrowser.exe      N/A      |\n",
      "|    0   N/A  N/A     31560    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (2.2.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (0.17.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (2.2.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda: 0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "DEVICE =  \"cuda: 0\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"FacebookAI/roberta-base\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, Value, ClassLabel, Features\n",
    "\n",
    "my_dataset = load_dataset(\"./Emotion_Dataset\", sep=\",\")\n",
    "# Creating a ClassLabel Object\n",
    "df = my_dataset[\"train\"].to_pandas()\n",
    "labels = ['sadness','joy','love','anger', 'fear', 'surprise']\n",
    "ClassLabels = ClassLabel(num_classes=len(labels), names=labels)\n",
    "\n",
    "# Mapping Labels to IDs\n",
    "def map_label2id(example):\n",
    "    example['label'] = ClassLabels.str2int(example['label'])\n",
    "    return example\n",
    "\n",
    "my_dataset= my_dataset.map(map_label2id, batched=True)\n",
    "\n",
    "# Casting label column to ClassLabel Object\n",
    "my_dataset = my_dataset.cast_column('label', ClassLabels)\n",
    "\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1995    3\n",
       "1996    3\n",
       "1997    1\n",
       "1998    1\n",
       "1999    4\n",
       "Name: label, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = my_dataset[\"train\"].to_pandas()\n",
    "X_val = my_dataset[\"validation\"].to_pandas()\n",
    "X_test = my_dataset[\"test\"].to_pandas()\n",
    "y_true = X_test.label\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = my_dataset[\"train\"].features\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {idx:features[\"label\"].int2str(idx) for idx in range(6)}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {v:k for k,v in id2label.items()}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    0.291625\n",
       "1    0.335125\n",
       "2    0.081500\n",
       "3    0.134937\n",
       "4    0.121063\n",
       "5    0.035750\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"label\"].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d06fd6e24d1449290d983d6d80e98d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alice\\Documents\\NLP\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\alice\\.cache\\huggingface\\hub\\models--FacebookAI--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4d654aafa24814992e13140b5e9271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527b6df779c4091b10794c1ee09c869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566caa94c8a04609ab170d470817ac2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d6920dd6f349619d78acaf60dde0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(examples):\n",
    "  return tokenizer(examples[\"text\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2ca262bab4e4287854782cdc9b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dd0a187db94190a41cb66d8c9e42e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453346dfffb41d68f59de16b12e6233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset = my_dataset.map(tokenize_text, batched=True)\n",
    "my_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7084, 0.6649, 0.9185, 0.8651, 0.8789, 0.9643], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 - (X_train[\"label\"].value_counts().sort_index() / len(X_train))).values #assigning high weight to the rare classes and low weight to the common classes to balance it out as there is an imbalance in the dataset\n",
    "class_weights\n",
    "\n",
    "import torch\n",
    "\n",
    "class_weights = torch.from_numpy(class_weights).float()\n",
    "class_weights = class_weights.to(\"cuda\")\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = my_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedLossTrainer(Trainer):\n",
    "  def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    # Feed inputs to model and extract logits\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.get(\"logits\")\n",
    "    # Extract labels\n",
    "    labels = inputs.get(\"labels\")\n",
    "    #Define loss function with class weights\n",
    "    loss_func=nn.CrossEntropyLoss(weight=class_weights)\n",
    "    # Compute loss\n",
    "    loss = loss_func(logits, labels)\n",
    "    return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04974715bbd4a00927049a7566a9a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
    "                                                          num_labels=6,\n",
    "                                                          id2label=id2label,\n",
    "                                                          label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  accuracy= accuracy_score(labels, preds)\n",
    "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "  return {\"f1\": f1, \"accuracy\" : accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (4.38.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (2.2.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from transformers[torch]) (0.28.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (2.2.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alice\\documents\\nlp\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch]\n",
    "%pip install accelerate -U\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "logging_steps = len(my_dataset[\"train\"])\n",
    "output_dir = \"/content/drive/MyDrive/Emotion_Output\"\n",
    "training_args = TrainingArguments(output_dir=output_dir,\n",
    "                                  num_train_epochs=6,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alice\\Documents\\NLP\\.venv\\Lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = WeightedLossTrainer(model=model,\n",
    "                              args=training_args,\n",
    "                              compute_metrics=compute_metrics,\n",
    "                              train_dataset=my_dataset[\"train\"],\n",
    "                              eval_dataset= my_dataset[\"validation\"],\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, tokenizer):\n",
    "    y_pred = []\n",
    "    none_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        \n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-classification\",\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['label'].split(\"=\")[-1]\n",
    "        #print(result)\n",
    "        #print(answer)\n",
    "        if \"sadness\" in answer:\n",
    "            y_pred.append(0)\n",
    "        elif \"joy\" in answer:\n",
    "            y_pred.append(1)\n",
    "        elif \"love\" in answer:\n",
    "            y_pred.append(2)\n",
    "        elif \"anger\" in answer:\n",
    "            y_pred.append(3)\n",
    "        elif \"fear\" in answer:\n",
    "            y_pred.append(4)\n",
    "        elif \"surprise\" in answer:\n",
    "            y_pred.append(5)\n",
    "        else:\n",
    "            y_pred.append(6)\n",
    "            none_pred.append(answer)\n",
    "        # print(none_pred)\n",
    "    return y_pred, none_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "\n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels output: {0,1,2,3,4,5}\n",
    "\n",
    "    # nested for loops\n",
    "    for label in unique_labels:\n",
    "        # will output a list of the index of one emotion at a time\n",
    "        label_indices = [i for i in range(len(y_true))\n",
    "                         if y_true[i] == label]\n",
    "        # will output the list of one emotion\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        # label_y_true = [label for i in range(len(y_true))]\n",
    "        # will output list of the predicted emotion in the same order as label_y_true\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2, 3, 4, 5, 6])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:05<00:00, 15.94it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred, none_pred = predict(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alice\\Documents\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.176\n",
      "Accuracy for label 0: 0.291\n",
      "Accuracy for label 1: 0.053\n",
      "Accuracy for label 2: 0.000\n",
      "Accuracy for label 3: 0.000\n",
      "Accuracy for label 4: 0.652\n",
      "Accuracy for label 5: 0.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.29      0.28       581\n",
      "           1       0.43      0.05      0.09       695\n",
      "           2       0.00      0.00      0.00       159\n",
      "           3       0.00      0.00      0.00       275\n",
      "           4       0.11      0.65      0.19       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.18      2000\n",
      "   macro avg       0.14      0.17      0.09      2000\n",
      "weighted avg       0.24      0.18      0.14      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[169  20   0   2 390   0   0]\n",
      " [218  37   0   1 439   0   0]\n",
      " [ 56   8   0   0  95   0   0]\n",
      " [ 84   9   0   0 182   0   0]\n",
      " [ 67  10   0   1 146   0   0]\n",
      " [ 19   3   0   0  44   0   0]\n",
      " [  0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alice\\Documents\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alice\\Documents\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13751a33c5934d66ad79d48b5c74101d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e6cfc04d5a41f29fa4fdb24eb8e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26720038056373596, 'eval_f1': 0.9080498475369141, 'eval_accuracy': 0.906, 'eval_runtime': 37.1621, 'eval_samples_per_second': 53.818, 'eval_steps_per_second': 0.861, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /content/drive/MyDrive/Emotion_Output\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da769979d37461da3f3f3f4273853e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18085992336273193, 'eval_f1': 0.9299562686351285, 'eval_accuracy': 0.93, 'eval_runtime': 37.0703, 'eval_samples_per_second': 53.952, 'eval_steps_per_second': 0.863, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2324697639440dfbab9392865c069d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17214852571487427, 'eval_f1': 0.9330425520880335, 'eval_accuracy': 0.9315, 'eval_runtime': 37.9522, 'eval_samples_per_second': 52.698, 'eval_steps_per_second': 0.843, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /content/drive/MyDrive/Emotion_Output\\checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41c4ae535054f05b0be7a6e5f72ca35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14081747829914093, 'eval_f1': 0.94149151738001, 'eval_accuracy': 0.941, 'eval_runtime': 38.0036, 'eval_samples_per_second': 52.627, 'eval_steps_per_second': 0.842, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5d96b7b63b4b34921ded53714647b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13884671032428741, 'eval_f1': 0.9398946686175306, 'eval_accuracy': 0.939, 'eval_runtime': 38.6136, 'eval_samples_per_second': 51.795, 'eval_steps_per_second': 0.829, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory /content/drive/MyDrive/Emotion_Output\\checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c1cc77dfed47ec8616649ceda3f525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14256718754768372, 'eval_f1': 0.9432912919473561, 'eval_accuracy': 0.9425, 'eval_runtime': 38.0619, 'eval_samples_per_second': 52.546, 'eval_steps_per_second': 0.841, 'epoch': 6.0}\n",
      "{'train_runtime': 5756.3393, 'train_samples_per_second': 16.677, 'train_steps_per_second': 0.261, 'train_loss': 0.23213614908854166, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.23213614908854166, metrics={'train_runtime': 5756.3393, 'train_samples_per_second': 16.677, 'train_steps_per_second': 0.261, 'train_loss': 0.23213614908854166, 'epoch': 6.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train() #changing the setting for training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a85b3d3685445f6ac6c173805fbcf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 6.8242188 , -1.2421875 , -1.6777344 , -1.1679688 , -2.3613281 ,\n",
       "        -1.3349609 ],\n",
       "       [ 6.9257812 , -1.5898438 , -1.8212891 , -1.1103516 , -1.8017578 ,\n",
       "        -1.4833984 ],\n",
       "       [ 6.7734375 , -1.9853516 , -1.6376953 , -1.0498047 , -1.7128906 ,\n",
       "        -1.3642578 ],\n",
       "       ...,\n",
       "       [-1.1777344 ,  7.0742188 , -0.90283203, -1.5400391 , -1.6699219 ,\n",
       "        -0.8457031 ],\n",
       "       [-1.5126953 ,  7.1835938 , -0.84472656, -1.4384766 , -1.2529297 ,\n",
       "        -1.0322266 ],\n",
       "       [-1.8066406 , -1.6054688 , -1.6992188 , -2.0175781 ,  3.7226562 ,\n",
       "         4.234375  ]], dtype=float32), label_ids=array([0, 0, 0, ..., 1, 1, 4], dtype=int64), metrics={'test_loss': 0.1556072235107422, 'test_f1': 0.927315549315068, 'test_accuracy': 0.926, 'test_runtime': 37.4728, 'test_samples_per_second': 53.372, 'test_steps_per_second': 0.854})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() #changing the setting for testing\n",
    "pred = trainer.predict(my_dataset[\"test\"])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95df9b5b26744b993af37276698a02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1556072235107422,\n",
       " 'eval_f1': 0.927315549315068,\n",
       " 'eval_accuracy': 0.926,\n",
       " 'eval_runtime': 37.5828,\n",
       " 'eval_samples_per_second': 53.216,\n",
       " 'eval_steps_per_second': 0.851,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(my_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [02:05<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.926\n",
      "Accuracy for label 0: 0.960\n",
      "Accuracy for label 1: 0.917\n",
      "Accuracy for label 2: 0.950\n",
      "Accuracy for label 3: 0.949\n",
      "Accuracy for label 4: 0.835\n",
      "Accuracy for label 5: 0.879\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       581\n",
      "           1       0.98      0.92      0.95       695\n",
      "           2       0.78      0.95      0.86       159\n",
      "           3       0.92      0.95      0.93       275\n",
      "           4       0.92      0.83      0.87       224\n",
      "           5       0.68      0.88      0.77        66\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.87      0.91      0.89      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[558   4   0  12   7   0   0]\n",
      " [  5 637  43   2   1   7   0]\n",
      " [  0   8 151   0   0   0   0]\n",
      " [  8   2   0 261   4   0   0]\n",
      " [  7   0   0  10 187  20   0]\n",
      " [  3   0   0   0   5  58   0]\n",
      " [  0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred, none_pred = predict(model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
